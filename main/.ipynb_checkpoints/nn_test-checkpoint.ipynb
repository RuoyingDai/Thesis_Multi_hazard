{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b55d6b",
   "metadata": {},
   "source": [
    "### Example of training neural network for multi hazard project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eafb93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=False)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "#!pip install shap\n",
    "import shap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#!pip uninstall keras-nightly\n",
    "from tensorflow import keras\n",
    "import re\n",
    "from bayes_opt import BayesianOptimization\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6fec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moved all helper functions (such as plot functions) to utils/utils.py\n",
    "# Here we import them\n",
    "from utils.utils import (R_squared, plot_2_metric_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a685fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'R_squared' from 'utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Moved all model functions to utils/model.py\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (my_model0, my_model)\n",
      "File \u001b[0;32m~/Thesis_Multi_hazard/main/utils/model.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m R_squared\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_model\u001b[39m(learning_rate, regularization,layer):\n\u001b[1;32m      5\u001b[0m     num_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'R_squared' from 'utils' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Moved all model functions to utils/model.py\n",
    "from utils.model import (my_model0, my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92520cd",
   "metadata": {},
   "source": [
    "### Load the data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/v27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['int_drought',\n",
    "       'int_earthquake', 'int_extreme_temp',\n",
    "       'int_flood', 'int_landslide',\n",
    "       'int_tropical', 'int_unknown_storm', 'int_conv_storm',\n",
    "        # background variables\n",
    "        'mm_fault_density', 'mm_slope',\n",
    "          'mm_road_density',\n",
    "        # vulnerability variables\n",
    "        'multi_phdi', 'multi_ppp','single_phdi', 'single_ppp']]\n",
    "y = df['ln10_Total_Damage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data 80% training and 20% testin\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053bc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89287688",
   "metadata": {},
   "source": [
    "### YS: Here the model is not defined yet -- please fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b5b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_summary = shap.kmeans(X_train, 10)\n",
    "ex = shap.KernelExplainer(model.predict, X_train_summary)\n",
    "#%%\n",
    "# Dimension: last layer neuron # * sample # * feature #\n",
    "shap_values = ex.shap_values(X_test.iloc[0:50,:])\n",
    "# average over all neurons in the last layer\n",
    "\n",
    "s = np.mean(shap_values, axis = 0)\n",
    "shap.summary_plot(s, X_test.iloc[0:50,:])\n",
    "\n",
    "#%% interaction term\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "shap.dependence_plot(\"multi_phdi\", s, X_test.iloc[0:50,:], interaction_index=\"mm_slope\", show=False,cmap=plt.get_cmap(\"bwr\"),dot_size=40)\n",
    "plt.savefig('figures/trial_shap2.png', format='png', dpi=150, bbox_inches='tight')\n",
    "#%%\n",
    "# Save and plot mean of 3 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5080f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67499eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# run my_model\n",
    "#%%\n",
    "learning_rate = 2e-3\n",
    "regularization = 6\n",
    "layer = 1\n",
    "num_run = 1\n",
    "history = [[] for i in range(num_run)]\n",
    "val_metric = 0\n",
    "for run_idx  in range(num_run):\n",
    "    print('Same setting run: {}'.format(run_idx + 1))\n",
    "    history_run = my_model0(learning_rate, regularization,layer, run_idx)\n",
    "    history[run_idx] = history_run\n",
    "    val_metric += history_run['val_loss'][-1]\n",
    "p1 = str(learning_rate).replace(\".\", \"_\" )# learning rate\n",
    "# hyperparameter 2\n",
    "p2 = str(regularization).replace(\".\", \"_\")# regularization\n",
    "p3 = round(layer) # activation function\n",
    "with open('figures/adagrad_lr{}_reg{}_lay{}'.format(p1[:5],p2[:5],p3), \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cb413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b243d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b3c2ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   layer   | learni... | regula... |\n",
      "-------------------------------------------------------------\n",
      "Same setting run: 1\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'R_squared' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/gpflow/lib/python3.8/site-packages/bayes_opt/target_space.py:191\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.6236203565420875, 0.047585001014085894, 24.6398788362281)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m pbounds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;241m5e-2\u001b[39m),\n\u001b[1;32m      3\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularization\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m),\n\u001b[1;32m      4\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m2.5\u001b[39m),\n\u001b[1;32m      5\u001b[0m            \u001b[38;5;66;03m#'drop_out_rate': (0.2, 0.5),\u001b[39;00m\n\u001b[1;32m      6\u001b[0m            \u001b[38;5;66;03m#'momentum': (0.1, 0.5)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m            }\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m      9\u001b[0m     f \u001b[38;5;241m=\u001b[39m my_model,\n\u001b[1;32m     10\u001b[0m     pbounds \u001b[38;5;241m=\u001b[39m pbounds,\n\u001b[1;32m     11\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_points\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mres):\n",
      "File \u001b[0;32m~/miniforge3/envs/gpflow/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py:305\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    303\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    304\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/miniforge3/envs/gpflow/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py:200\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/miniforge3/envs/gpflow/lib/python3.8/site-packages/bayes_opt/target_space.py:194\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 194\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/Thesis_Multi_hazard/main/utils/model.py:9\u001b[0m, in \u001b[0;36mmy_model\u001b[0;34m(learning_rate, regularization, layer)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run_idx  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_run):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSame setting run: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(run_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m     history_run \u001b[38;5;241m=\u001b[39m \u001b[43mmy_model0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     history[run_idx] \u001b[38;5;241m=\u001b[39m history_run\n\u001b[1;32m     11\u001b[0m     val_metric \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m history_run[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Thesis_Multi_hazard/main/utils/model.py:62\u001b[0m, in \u001b[0;36mmy_model0\u001b[0;34m(lr, reg, lay, run_idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m   model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m                           activity_regularizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mL1L2(l1\u001b[38;5;241m=\u001b[39mreg\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, l2\u001b[38;5;241m=\u001b[39mreg\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1e-1\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     47\u001b[0m ])\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;66;03m#Compile the model\u001b[39;00m\n\u001b[1;32m     50\u001b[0m   model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     51\u001b[0m       loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError(),\u001b[38;5;66;03m# it does not work if () is not here.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m       \u001b[38;5;66;03m#optimizer = tf.keras.optimizers.SGD(learning_rate= 0.005,\u001b[39;00m\n\u001b[1;32m     53\u001b[0m       \u001b[38;5;66;03m#                                    momentum = momentum),# 0.05/0.02\u001b[39;00m\n\u001b[1;32m     54\u001b[0m       optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(\n\u001b[1;32m     55\u001b[0m         learning_rate \u001b[38;5;241m=\u001b[39m lr,\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;66;03m#learning_rate=0.001,# default is 0.001\u001b[39;00m\n\u001b[1;32m     57\u001b[0m         initial_accumulator_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     58\u001b[0m         epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-07\u001b[39m,\n\u001b[1;32m     59\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdagrad\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     60\u001b[0m         ),\n\u001b[1;32m     61\u001b[0m       metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 62\u001b[0m           \u001b[43mR_squared\u001b[49m,\n\u001b[1;32m     63\u001b[0m       ]\n\u001b[1;32m     64\u001b[0m   )\n\u001b[1;32m     66\u001b[0m   overfitCallback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     67\u001b[0m                                                  min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m,\n\u001b[1;32m     68\u001b[0m                                                  patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     69\u001b[0m                                                  mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m   history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train), np\u001b[38;5;241m.\u001b[39marray(y_train),\n\u001b[1;32m     71\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     72\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m           validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     76\u001b[0m   callbacks\u001b[38;5;241m=\u001b[39m[overfitCallback])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'R_squared' is not defined"
     ]
    }
   ],
   "source": [
    "#%% Bayes Optimization\n",
    "pbounds = {'learning_rate': (1e-3, 5e-2),\n",
    "           'regularization': (10,30),\n",
    "           'layer':(-0.5, 2.5),\n",
    "           #'drop_out_rate': (0.2, 0.5),\n",
    "           #'momentum': (0.1, 0.5)\n",
    "           }\n",
    "optimizer = BayesianOptimization(\n",
    "    f = my_model,\n",
    "    pbounds = pbounds,\n",
    "    random_state = 42)\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points = 1,\n",
    "    n_iter = 4)\n",
    "#%%\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print('Iteration {}: \\n\\t{}'.format(i, res))\n",
    "    break\n",
    "\n",
    "#%%\n",
    "\n",
    "#file_name = \"adagrad_lr1_985_reg41_44_lay1\"#1.48/1.39/crazy r2\n",
    "#file_name = \"adagrad_lr0_061_reg5_541_lay1\"#1.45/0.75/0.6/0.4\n",
    "aaa = pickle.load(open( \"figures/\"+file_name, \"rb\"))\n",
    "#%%\n",
    "plt.plot(aaa[0]['loss'])\n",
    "#%%\n",
    "plt.plot(aaa[0]['val_loss'])\n",
    "#%%\n",
    "plt.plot(aaa[0]['R_squared'])\n",
    "#%%\n",
    "plt.plot(aaa[0]['val_R_squared'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2fe7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7048fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e0491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68309142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38173f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c4e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d4cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
